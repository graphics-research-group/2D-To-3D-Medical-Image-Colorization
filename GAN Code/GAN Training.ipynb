{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "import sys\r\n",
    "import tqdm \r\n",
    "import time\r\n",
    "import math\r\n",
    "import torch\r\n",
    "import datetime\r\n",
    "import itertools\r\n",
    "import torchvision\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import torch.nn as nn\r\n",
    "import skimage.io as io\r\n",
    "import SimpleITK as sitk\r\n",
    "import torch.optim as optim\r\n",
    "import torch.nn.functional as F\r\n",
    "\r\n",
    "from tensorboardX import SummaryWriter\r\n",
    "from torch.utils.data import Dataset, DataLoader\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "from all_models import *\r\n",
    "\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "np.random.seed(42)\r\n",
    "\r\n",
    "custom_name = 'masked_cryo_final_gamma_zoom_fcn3d_resumed'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generator"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "generator = FCN3D().to(device)\r\n",
    "# generator.load_state_dict(torch.load('./bce_fcn_gamma_zoom/2020-03-11 04:22:17.616635_masked_cryo_final_gamma_zoom_fcn3d_resumed/models/50_0_g_.pt')) # final model saved"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Discriminator"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "discriminator = Discriminator_old(dim=32, sig=True).to(device)\r\n",
    "# discriminator.load_state_dict(torch.load('./bce_fcn_gamma_zoom/2020-03-11 04:22:17.616635_masked_cryo_final_gamma_zoom_fcn3d_resumed/models/50_0_d_.pt'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataloader"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Directory structure is as follows:\n",
    "- ROOT DIR\n",
    "    - MRI DIR: Containing all 3D MRI sub-volumes\n",
    "    - CRYO DIR: Containing all 3D Poisson Cryo sub-volumes (Poisson Generation Code Available in MATLAB)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "DATA_DIR = './volume_generator/'\r\n",
    "MRI_DIR = 'random_gamma_zoom_volume_mri_16'\r\n",
    "CRYO_DIR = 'random_gamma_zoom_volume_poisson_16'\r\n",
    "\r\n",
    "mri_list = os.listdir(DATA_DIR+MRI_DIR)\r\n",
    "mri_list.sort()\r\n",
    "mri_list = mri_list[::2]\r\n",
    "\r\n",
    "cryo_list = os.listdir(DATA_DIR+CRYO_DIR)\r\n",
    "cryo_list.sort()\r\n",
    "cryo_list = cryo_list[::2]\r\n",
    "\r\n",
    "\r\n",
    "train_mr, test_mr, train_cryo, test_cryo = train_test_split(mri_list, cryo_list, test_size=0.1, random_state=42)\r\n",
    "\r\n",
    "\r\n",
    "batch = 8\r\n",
    "\r\n",
    "\r\n",
    "class VolumeDataset(Dataset):\r\n",
    "    def __init__(self, X, Y, root, size = (32,32,32)):\r\n",
    "        self.greypath = os.path.join(root, MRI_DIR)\r\n",
    "        self.colorpath = os.path.join(root, CRYO_DIR)\r\n",
    "\r\n",
    "        self.greyimg = X\r\n",
    "        self.colorimg = Y\r\n",
    "        self.imgsize = size\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.greyimg)\r\n",
    "\r\n",
    "    def __getitem__(self, index):\r\n",
    "        mri = sitk.ReadImage(os.path.join(self.greypath, self.greyimg[index]))\r\n",
    "        mri = np.nan_to_num(sitk.GetArrayFromImage(mri))\r\n",
    "        \r\n",
    "        mri = torch.from_numpy(mri)\r\n",
    "        \r\n",
    "        cryo = sitk.ReadImage(os.path.join(self.colorpath, self.colorimg[index]))\r\n",
    "        cryo = np.nan_to_num(sitk.GetArrayFromImage(cryo))\r\n",
    "        cryo = torch.from_numpy(cryo)\r\n",
    "\r\n",
    "        return mri, cryo\r\n",
    "\r\n",
    "\r\n",
    "train_dataset = VolumeDataset(train_mr, train_cryo, DATA_DIR)\r\n",
    "train_dataloader = DataLoader(train_dataset, num_workers=2, shuffle=False, batch_size=batch)\r\n",
    "\r\n",
    "test_dataset = VolumeDataset(test_mr, test_cryo, DATA_DIR)\r\n",
    "test_dataloader = DataLoader(test_dataset, num_workers=2, shuffle=False, batch_size=batch)\r\n",
    "\r\n",
    "for i, data in enumerate(train_dataloader):\r\n",
    "    print(data[1].shape)\r\n",
    "    break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Optimizers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lr = 1.0e-4\r\n",
    "momentum = 0.95"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(momentum, 0.999))\r\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(momentum, 0.999))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "criterion_gan = nn.BCELoss().to(device)\r\n",
    "criterion_content = SSIM(device).to(device)\r\n",
    "criterion_l1 = nn.L1Loss().to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print_freq = 10\r\n",
    "max_epoch = 1002\r\n",
    "save_freq = 1000"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ROOT_DIR = './bce_fcn_gamma_zoom/'\r\n",
    "now = str(datetime.datetime.now()) + '_' + custom_name\r\n",
    "\r\n",
    "if not os.path.exists(ROOT_DIR):\r\n",
    "    os.makedirs(ROOT_DIR)\r\n",
    "\r\n",
    "if not os.path.exists(ROOT_DIR + now):\r\n",
    "    os.makedirs(ROOT_DIR + now)\r\n",
    "\r\n",
    "LOG_DIR = ROOT_DIR + now + '/logs/'\r\n",
    "if not os.path.exists(LOG_DIR):\r\n",
    "    os.makedirs(LOG_DIR)\r\n",
    "\r\n",
    "OUTPUTS_DIR = ROOT_DIR  + now + '/outputs/'\r\n",
    "if not os.path.exists(OUTPUTS_DIR):\r\n",
    "    os.makedirs(OUTPUTS_DIR)\r\n",
    "\r\n",
    "MODEL_DIR = ROOT_DIR + now + '/models/'\r\n",
    "if not os.path.exists(MODEL_DIR):\r\n",
    "    os.makedirs(MODEL_DIR)\r\n",
    "\r\n",
    "summary_writer = SummaryWriter(LOG_DIR)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lambda_gan = 1.0\r\n",
    "lambda_content = -1.0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for epoch in range(max_epoch):\r\n",
    "    for i, data in enumerate(train_dataloader):\r\n",
    "        mri = data[0].unsqueeze(1).float().to(device)\r\n",
    "        cryo = data[1].unsqueeze(1).float().to(device)\r\n",
    "        \r\n",
    "        gen_cryo = generator(mri)\r\n",
    "        \r\n",
    "        # print(gen_cryo.max(), gen_cryo.min())\r\n",
    "        # # print(mri.max\r\n",
    "        # import ipdb; ipdb.set_trace()\r\n",
    "        # exit()\r\n",
    "        real_cryo_prob = discriminator(cryo)\r\n",
    "        fake_cryo_prob = discriminator(gen_cryo)\r\n",
    "        \r\n",
    "        truth = torch.ones(mri.shape[0],1).to(device)\r\n",
    "        fake = torch.zeros(mri.shape[0],1).to(device)\r\n",
    "        \r\n",
    "        optimizer_G.zero_grad()\r\n",
    "        loss_gan = criterion_gan(fake_cryo_prob, truth) * lambda_gan\r\n",
    "        loss_content = criterion_content(gen_cryo, cryo) * lambda_content + criterion_l1(gen_cryo, cryo) * math.fabs(lambda_content)\r\n",
    "        loss_gen = loss_gan + loss_content\r\n",
    "        loss_gen.backward(retain_graph=True)\r\n",
    "        \r\n",
    "        optimizer_G.step()\r\n",
    "        \r\n",
    "        optimizer_D.zero_grad()\r\n",
    "        loss_real = criterion_gan(real_cryo_prob, truth)\r\n",
    "        loss_fake = criterion_gan(fake_cryo_prob, fake)\r\n",
    "        loss_dis = (loss_real + loss_fake) * lambda_gan / 2\r\n",
    "        if loss_dis.item() > 0.5 or epoch > 10:\r\n",
    "            loss_dis.backward(retain_graph=True)            \r\n",
    "            optimizer_D.step()\r\n",
    "        \r\n",
    "        summary_writer.add_scalar('Discriminator Loss', loss_dis.item())\r\n",
    "        summary_writer.add_scalar('Content Loss', loss_content.item())\r\n",
    "        summary_writer.add_scalar('Generator Loss', loss_gen.item())\r\n",
    "\r\n",
    "        print('Epoch: {}, Iteration: {}, Content Loss: {}, Generator Loss: {}, Discriminator Loss: {}'.format(epoch, i, loss_content.item()\r\n",
    "                                                                                                                , loss_gan.item(), loss_dis.item()))\r\n",
    "\r\n",
    "        if i % save_freq == 0:\r\n",
    "            print('\\n\\n Saving model and output \\n\\n')\r\n",
    "            if epoch % 50 == 0:\r\n",
    "                torch.save(generator.state_dict(), MODEL_DIR+'{}_{}_g_.pt'.format(epoch,i))\r\n",
    "                torch.save(discriminator.state_dict(), MODEL_DIR+'{}_{}_d_.pt'.format(epoch,i))\r\n",
    "                \r\n",
    "                torch.save(optimizer_G.state_dict(), MODEL_DIR+'{}_{}_g_optim_mr2gr.pt'.format(epoch,i))\r\n",
    "                torch.save(optimizer_D.state_dict(), MODEL_DIR+'{}_{}_d_optim_mr2gr.pt'.format(epoch,i))\r\n",
    "            \r\n",
    "            for j in range(gen_cryo.shape[0]):\r\n",
    "                fake_cryo = gen_cryo[j,:,:,:,:]\r\n",
    "                fake_cryo = fake_cryo.permute(1,2,3,0)\r\n",
    "                fake_cryo = fake_cryo.cpu().detach().numpy()\r\n",
    "                cryo_vol = sitk.GetImageFromArray(fake_cryo)\r\n",
    "                sitk.WriteImage(cryo_vol, OUTPUTS_DIR+'{}_{}_{}_cryo_gen.mhd'.format(epoch,i,j))\r\n",
    "                \r\n",
    "                fake_mri = mri[j,0,:,:,:]\r\n",
    "                fake_mri = fake_mri.cpu().detach().numpy()\r\n",
    "                mri_vol = sitk.GetImageFromArray(fake_mri)\r\n",
    "                sitk.WriteImage(mri_vol, OUTPUTS_DIR+'{}_{}_{}mri_gt.mhd'.format(epoch,i,j))\r\n",
    "\r\n",
    "                rev_cryo = cryo[j,:,:,:,:]\r\n",
    "                rev_cryo = rev_cryo.permute([1,2,3,0])\r\n",
    "                rev_cryo = rev_cryo.cpu().detach().numpy()\r\n",
    "                rev_vol = sitk.GetImageFromArray(rev_cryo)\r\n",
    "                sitk.WriteImage(rev_vol, OUTPUTS_DIR+'{}_{}_{}cryo_gt.mhd'.format(epoch,i,j))\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}